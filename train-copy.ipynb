{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\ESPB\\miniconda3\\envs\\ml\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Flatten, Input, Concatenate\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_train_gen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    horizontal_flip=True,\n",
    "    brightness_range=(0.5, 0.6),\n",
    ")\n",
    "\n",
    "eyes_train_gen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    horizontal_flip=True,\n",
    "    brightness_range=(0.5, 0.6),\n",
    ")\n",
    "\n",
    "mouth_train_gen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    horizontal_flip=True,\n",
    "    brightness_range=(0.5, 0.6),\n",
    ")\n",
    "\n",
    "face_test_gen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    horizontal_flip=True,\n",
    "    brightness_range=(0.5, 0.6),\n",
    ")\n",
    "\n",
    "eyes_test_gen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    horizontal_flip=True,\n",
    "    brightness_range=(0.5, 0.6),\n",
    ")\n",
    "\n",
    "mouth_test_gen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    horizontal_flip=True,\n",
    "    brightness_range=(0.5, 0.6),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 776 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "face_train_generator = face_train_gen.flow_from_directory(\n",
    "    'data/train/face_train/',\n",
    "    target_size=(38, 38),\n",
    "    batch_size=64,\n",
    "    color_mode=\"grayscale\",\n",
    "    class_mode=\"categorical\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 777 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "eyes_train_generator = eyes_train_gen.flow_from_directory(\n",
    "    'data/train/eyes_train/',\n",
    "    target_size=(30, 62),\n",
    "    batch_size=64,\n",
    "    color_mode=\"grayscale\",\n",
    "    class_mode=\"categorical\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 769 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "mouth_train_generator = mouth_train_gen.flow_from_directory(\n",
    "    'data/train/mouth_train/',\n",
    "    target_size=(30, 38),\n",
    "    batch_size=64,\n",
    "    color_mode=\"grayscale\",\n",
    "    class_mode=\"categorical\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 181 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "face_valid_generator = face_test_gen.flow_from_directory(\n",
    "    'data/test/face_test/',\n",
    "    target_size=(38, 38),\n",
    "    batch_size=64,\n",
    "    color_mode=\"grayscale\",\n",
    "    class_mode=\"categorical\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 181 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "eyes_valid_generator = eyes_test_gen.flow_from_directory(\n",
    "    'data/test/eyes_test/',\n",
    "    target_size=(30, 62),\n",
    "    batch_size=64,\n",
    "    color_mode=\"grayscale\",\n",
    "    class_mode=\"categorical\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 181 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "mouth_valid_generator = mouth_test_gen.flow_from_directory(\n",
    "    'data/test/mouth_test/',\n",
    "    target_size=(30, 38),\n",
    "    batch_size=64,\n",
    "    color_mode=\"grayscale\",\n",
    "    class_mode=\"categorical\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\ESPB\\miniconda3\\envs\\ml\\lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\ESPB\\miniconda3\\envs\\ml\\lib\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv_1 (Conv2D)             (None, 36, 36, 6)         60        \n",
      "                                                                 \n",
      " pool_1 (MaxPooling2D)       (None, 18, 18, 6)         0         \n",
      "                                                                 \n",
      " conv_2 (Conv2D)             (None, 16, 16, 16)        880       \n",
      "                                                                 \n",
      " pool_2 (MaxPooling2D)       (None, 8, 8, 16)          0         \n",
      "                                                                 \n",
      " conv_3 (Conv2D)             (None, 6, 6, 32)          4640      \n",
      "                                                                 \n",
      " pool_3 (MaxPooling2D)       (None, 3, 3, 32)          0         \n",
      "                                                                 \n",
      " face_flatten (Flatten)      (None, 288)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1024)              295936    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 7)                 7175      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 308691 (1.18 MB)\n",
      "Trainable params: 308691 (1.18 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#mean\n",
    "\n",
    "face_emotion_model = Sequential()\n",
    "\n",
    "face_emotion_model.add(Conv2D(6, kernel_size=(3, 3), activation='relu', input_shape=(38, 38, 1), name=\"conv_1\"))\n",
    "face_emotion_model.add(MaxPooling2D(pool_size=(2, 2), name=\"pool_1\"))\n",
    "\n",
    "face_emotion_model.add(Conv2D(16, kernel_size=(3, 3), activation='relu', input_shape=(18, 18, 6), name=\"conv_2\"))\n",
    "face_emotion_model.add(MaxPooling2D(pool_size=(2, 2), name=\"pool_2\"))\n",
    "\n",
    "face_emotion_model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(8, 8, 1), name=\"conv_3\"))\n",
    "face_emotion_model.add(MaxPooling2D(pool_size=(2, 2), name=\"pool_3\"))\n",
    "\n",
    "face_emotion_model.add(Flatten(name=\"face_flatten\"))\n",
    "\n",
    "face_emotion_model.add(Dense(1024, activation='relu'))\n",
    "face_emotion_model.add(Dropout(0.25))\n",
    "\n",
    "face_emotion_model.add(Dense(7, activation='softmax'))\n",
    "\n",
    "face_emotion_model.compile(loss='categorical_crossentropy', optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.0001, decay=1e-6), metrics=['accuracy'])\n",
    "\n",
    "face_emotion_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# face_train = face_emotion_model.fit(\n",
    "#     face_train_generator,\n",
    "#     steps_per_epoch= 776 // 64,\n",
    "#     epochs=50,\n",
    "#     validation_data=face_valid_generator,\n",
    "#     validation_steps= 181 // 64  \n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Training:\", face_train.history['accuracy'][-1])\n",
    "# print(\"Validation:\", face_train.history['val_accuracy'][-1])\n",
    "\n",
    "# plt.plot(face_train.history['accuracy'], label='Training Accuracy')\n",
    "# plt.plot(face_train.history['val_accuracy'], label='Validation Accuracy')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.ylabel('Accuracy')\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 24ms/step\n",
      "3/3 [==============================] - 0s 27ms/step\n"
     ]
    }
   ],
   "source": [
    "face_model = Model(inputs=face_emotion_model.input, outputs=face_emotion_model.get_layer('face_flatten').output)\n",
    "\n",
    "feature_face_train = face_model.predict(face_train_generator)\n",
    "\n",
    "feature_face_valid = face_model.predict(face_valid_generator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.00245339, 0.        , ..., 0.        , 0.        ,\n",
       "        0.03110036],\n",
       "       [0.        , 0.00517613, 0.        , ..., 0.        , 0.        ,\n",
       "        0.03522938],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.04287435],\n",
       "       ...,\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.04252308],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.03368181],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.04280861]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_face_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.02830746],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.05173616],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.03486076],\n",
       "       ...,\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.0223485 ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.04946333],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.04737936]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_face_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 28, 60, 6)         60        \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 14, 30, 6)         0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 12, 28, 16)        880       \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 6, 14, 16)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 4, 12, 32)         4640      \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPoolin  (None, 2, 6, 32)          0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " eyes_flatten (Flatten)      (None, 384)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1024)              394240    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 7)                 7175      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 406995 (1.55 MB)\n",
      "Trainable params: 406995 (1.55 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# variance\n",
    "\n",
    "eyes_emotion_model = Sequential()\n",
    "\n",
    "eyes_emotion_model.add(Conv2D(6, kernel_size=(3, 3), activation='relu', input_shape=(30, 62, 1)))\n",
    "eyes_emotion_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "eyes_emotion_model.add(Conv2D(16, kernel_size=(3, 3), activation='relu', input_shape=(14, 30, 6)))\n",
    "eyes_emotion_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "eyes_emotion_model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(6, 14, 16)))\n",
    "eyes_emotion_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "eyes_emotion_model.add(Flatten(name=\"eyes_flatten\"))\n",
    "\n",
    "eyes_emotion_model.add(Dense(1024, activation='relu'))\n",
    "eyes_emotion_model.add(Dropout(0.25))\n",
    "\n",
    "eyes_emotion_model.add(Dense(7, activation='softmax'))\n",
    "\n",
    "eyes_emotion_model.compile(loss='categorical_crossentropy', optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.0001, decay=1e-6), metrics=['accuracy'])\n",
    "\n",
    "eyes_emotion_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eyes_train = eyes_emotion_model.fit(\n",
    "#     eyes_train_generator,\n",
    "#     steps_per_epoch= 777 // 64,\n",
    "#     epochs=50,\n",
    "#     validation_data=eyes_valid_generator,\n",
    "#     validation_steps= 181 // 64  \n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Training:\", eyes_train.history['accuracy'][-1])\n",
    "# print(\"Validation:\", eyes_train.history['val_accuracy'][-1])\n",
    "\n",
    "# plt.plot(eyes_train.history['accuracy'], label='Training Accuracy')\n",
    "# plt.plot(eyes_train.history['val_accuracy'], label='Validation Accuracy')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.ylabel('Accuracy')\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 26ms/step\n",
      "3/3 [==============================] - 0s 31ms/step\n"
     ]
    }
   ],
   "source": [
    "eyes_feature = Model(inputs=eyes_emotion_model.input, outputs=eyes_emotion_model.get_layer('eyes_flatten').output)\n",
    "eyes_feature_train = eyes_feature.predict(eyes_train_generator)\n",
    "eyes_feature_valid = eyes_feature.predict(eyes_valid_generator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.04376709, 0.023609  , 0.        , ..., 0.05474539, 0.07716968,\n",
       "        0.00398259],\n",
       "       [0.09100535, 0.03196906, 0.00227964, ..., 0.08558277, 0.10613824,\n",
       "        0.0085912 ],\n",
       "       [0.06681338, 0.01503857, 0.        , ..., 0.07793393, 0.12560228,\n",
       "        0.01218364],\n",
       "       ...,\n",
       "       [0.01066854, 0.00771782, 0.0033514 , ..., 0.03693666, 0.08430764,\n",
       "        0.01056295],\n",
       "       [0.04906712, 0.03956955, 0.0261808 , ..., 0.09602828, 0.11424114,\n",
       "        0.00456636],\n",
       "       [0.03126717, 0.04145439, 0.02919935, ..., 0.05949473, 0.08304261,\n",
       "        0.01442613]], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eyes_feature_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.02444472, 0.01477559, 0.        , ..., 0.07625221, 0.13626257,\n",
       "        0.0175816 ],\n",
       "       [0.04574183, 0.019925  , 0.        , ..., 0.0480895 , 0.06982556,\n",
       "        0.01407338],\n",
       "       [0.04755373, 0.03046231, 0.        , ..., 0.06361931, 0.07749621,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.08632728, 0.01847691, 0.        , ..., 0.05485454, 0.08748418,\n",
       "        0.00604607],\n",
       "       [0.05603281, 0.02585249, 0.0074098 , ..., 0.04312242, 0.07905745,\n",
       "        0.00450944],\n",
       "       [0.08342797, 0.03281652, 0.        , ..., 0.08078352, 0.11223079,\n",
       "        0.00988454]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eyes_feature_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_3 (Conv2D)           (None, 28, 36, 6)         60        \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPoolin  (None, 14, 18, 6)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 12, 16, 16)        880       \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPoolin  (None, 6, 8, 16)          0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 4, 6, 32)          4640      \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPoolin  (None, 2, 3, 32)          0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " mouth_flatten (Flatten)     (None, 192)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1024)              197632    \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 7)                 7175      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 210387 (821.82 KB)\n",
      "Trainable params: 210387 (821.82 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# variance\n",
    "\n",
    "mouth_emotion_model = Sequential()\n",
    "\n",
    "mouth_emotion_model.add(Conv2D(6, kernel_size=(3, 3), activation='relu', input_shape=(30, 38, 1)))\n",
    "mouth_emotion_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "mouth_emotion_model.add(Conv2D(16, kernel_size=(3, 3), activation='relu', input_shape=(14, 18, 6)))\n",
    "mouth_emotion_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "mouth_emotion_model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(6, 8, 16)))\n",
    "mouth_emotion_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "mouth_emotion_model.add(Flatten(name=\"mouth_flatten\"))\n",
    "\n",
    "mouth_emotion_model.add(Dense(1024, activation='relu'))\n",
    "mouth_emotion_model.add(Dropout(0.25))\n",
    "\n",
    "mouth_emotion_model.add(Dense(7, activation='softmax'))\n",
    "\n",
    "mouth_emotion_model.compile(loss='categorical_crossentropy', optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.0001, decay=1e-6), metrics=['accuracy'])\n",
    "\n",
    "mouth_emotion_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mouth_train = mouth_emotion_model.fit(\n",
    "#     mouth_train_generator,\n",
    "#     steps_per_epoch= 769 // 64,\n",
    "#     epochs=50,\n",
    "#     validation_data=mouth_valid_generator,\n",
    "#     validation_steps= 181 // 64  \n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Training:\", mouth_train.history['accuracy'][-1])\n",
    "# print(\"Validation:\", mouth_train.history['val_accuracy'][-1])\n",
    "\n",
    "# plt.plot(mouth_train.history['accuracy'], label='Training Accuracy')\n",
    "# plt.plot(mouth_train.history['val_accuracy'], label='Validation Accuracy')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.ylabel('Accuracy')\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 25ms/step\n",
      "3/3 [==============================] - 0s 23ms/step\n"
     ]
    }
   ],
   "source": [
    "mouth_feature = Model(inputs=mouth_emotion_model.input, outputs=mouth_emotion_model.get_layer('mouth_flatten').output)\n",
    "mouth_feature_train = mouth_feature.predict(mouth_train_generator)\n",
    "mouth_feature_valid = mouth_feature.predict(mouth_valid_generator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.06550719, 0.        , ..., 0.        , 0.01006788,\n",
       "        0.02155416],\n",
       "       [0.        , 0.05277343, 0.        , ..., 0.        , 0.        ,\n",
       "        0.0051724 ],\n",
       "       [0.        , 0.08732902, 0.        , ..., 0.        , 0.01102345,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.        , 0.07799639, 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.05635453, 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.05523759, 0.        , ..., 0.        , 0.03310424,\n",
       "        0.        ]], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mouth_feature_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.03669132, 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.09890766, 0.        , ..., 0.        , 0.01336046,\n",
       "        0.        ],\n",
       "       [0.05000618, 0.10205302, 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.        , 0.06253731, 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.03359886, 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.06784614, 0.        , ..., 0.        , 0.        ,\n",
       "        0.01256201]], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mouth_feature_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenate_feature = Concatenate([feature_face_train, feature_face_valid, \n",
    "                                   eyes_feature_train, eyes_feature_valid, \n",
    "                                   mouth_feature_train, mouth_feature_valid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_feature_model = Sequential()\n",
    "all_feature_model.add(concatenate_feature)\n",
    "\n",
    "all_feature_model.add(Dense(864, activation='relu'))\n",
    "all_feature_model.add(Dropout(0.5))\n",
    "all_feature_model.add(Dense(7, activation='softmax'))\n",
    "\n",
    "all_feature_model.compile(loss='categorical_crossentropy', \n",
    "                          optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.0001, decay=1e-6), \n",
    "                          metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_feature_model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
