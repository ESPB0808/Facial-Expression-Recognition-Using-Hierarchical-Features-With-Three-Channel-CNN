{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Flatten, Input, Concatenate, Reshape\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_train_gen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    horizontal_flip=True,\n",
    "    brightness_range=(0.5, 0.6),\n",
    ")\n",
    "\n",
    "eyes_train_gen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    horizontal_flip=True,\n",
    "    brightness_range=(0.5, 0.6),\n",
    ")\n",
    "\n",
    "mouth_train_gen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    horizontal_flip=True,\n",
    "    brightness_range=(0.5, 0.6),\n",
    ")\n",
    "\n",
    "face_test_gen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    horizontal_flip=True,\n",
    "    brightness_range=(0.5, 0.6),\n",
    ")\n",
    "\n",
    "eyes_test_gen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    horizontal_flip=True,\n",
    "    brightness_range=(0.5, 0.6),\n",
    ")\n",
    "\n",
    "mouth_test_gen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    horizontal_flip=True,\n",
    "    brightness_range=(0.5, 0.6),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 776 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "face_train_generator = face_train_gen.flow_from_directory(\n",
    "    'data/train/face_train/',\n",
    "    target_size=(38, 38),\n",
    "    batch_size=64,\n",
    "    color_mode=\"grayscale\",\n",
    "    class_mode=\"categorical\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 777 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "eyes_train_generator = eyes_train_gen.flow_from_directory(\n",
    "    'data/train/eyes_train/',\n",
    "    target_size=(30, 62),\n",
    "    batch_size=64,\n",
    "    color_mode=\"grayscale\",\n",
    "    class_mode=\"categorical\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 769 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "mouth_train_generator = mouth_train_gen.flow_from_directory(\n",
    "    'data/train/mouth_train/',\n",
    "    target_size=(30, 38),\n",
    "    batch_size=64,\n",
    "    color_mode=\"grayscale\",\n",
    "    class_mode=\"categorical\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 181 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "face_valid_generator = face_test_gen.flow_from_directory(\n",
    "    'data/test/face_test/',\n",
    "    target_size=(38, 38),\n",
    "    batch_size=64,\n",
    "    color_mode=\"grayscale\",\n",
    "    class_mode=\"categorical\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 181 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "eyes_valid_generator = eyes_test_gen.flow_from_directory(\n",
    "    'data/test/eyes_test/',\n",
    "    target_size=(30, 62),\n",
    "    batch_size=64,\n",
    "    color_mode=\"grayscale\",\n",
    "    class_mode=\"categorical\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 181 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "mouth_valid_generator = mouth_test_gen.flow_from_directory(\n",
    "    'data/test/mouth_test/',\n",
    "    target_size=(30, 38),\n",
    "    batch_size=64,\n",
    "    color_mode=\"grayscale\",\n",
    "    class_mode=\"categorical\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv_1 (Conv2D)             (None, 36, 36, 6)         60        \n",
      "                                                                 \n",
      " pool_1 (MaxPooling2D)       (None, 18, 18, 6)         0         \n",
      "                                                                 \n",
      " conv_2 (Conv2D)             (None, 16, 16, 16)        880       \n",
      "                                                                 \n",
      " pool_2 (MaxPooling2D)       (None, 8, 8, 16)          0         \n",
      "                                                                 \n",
      " conv_3 (Conv2D)             (None, 6, 6, 32)          4640      \n",
      "                                                                 \n",
      " pool_3 (MaxPooling2D)       (None, 3, 3, 32)          0         \n",
      "                                                                 \n",
      " face_flatten (Flatten)      (None, 288)               0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 1024)              295936    \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 7)                 7175      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 308691 (1.18 MB)\n",
      "Trainable params: 308691 (1.18 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#mean\n",
    "\n",
    "face_emotion_model = Sequential()\n",
    "\n",
    "face_emotion_model.add(Conv2D(6, kernel_size=(3, 3), activation='relu', input_shape=(38, 38, 1), name=\"conv_1\"))\n",
    "face_emotion_model.add(MaxPooling2D(pool_size=(2, 2), name=\"pool_1\"))\n",
    "\n",
    "face_emotion_model.add(Conv2D(16, kernel_size=(3, 3), activation='relu', input_shape=(18, 18, 6), name=\"conv_2\"))\n",
    "face_emotion_model.add(MaxPooling2D(pool_size=(2, 2), name=\"pool_2\"))\n",
    "\n",
    "face_emotion_model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(8, 8, 1), name=\"conv_3\"))\n",
    "face_emotion_model.add(MaxPooling2D(pool_size=(2, 2), name=\"pool_3\"))\n",
    "\n",
    "face_emotion_model.add(Flatten(name=\"face_flatten\"))\n",
    "\n",
    "face_emotion_model.add(Dense(1024, activation='relu'))\n",
    "face_emotion_model.add(Dropout(0.25))\n",
    "\n",
    "face_emotion_model.add(Dense(7, activation='softmax'))\n",
    "\n",
    "face_emotion_model.compile(loss='categorical_crossentropy', optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.0001, decay=1e-6), metrics=['accuracy'])\n",
    "\n",
    "face_emotion_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_6 (Conv2D)           (None, 28, 60, 6)         60        \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPoolin  (None, 14, 30, 6)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 12, 28, 16)        880       \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPoolin  (None, 6, 14, 16)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 4, 12, 32)         4640      \n",
      "                                                                 \n",
      " max_pooling2d_8 (MaxPoolin  (None, 2, 6, 32)          0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " eyes_flatten (Flatten)      (None, 384)               0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 1024)              394240    \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 7)                 7175      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 406995 (1.55 MB)\n",
      "Trainable params: 406995 (1.55 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# variance\n",
    "\n",
    "eyes_emotion_model = Sequential()\n",
    "\n",
    "eyes_emotion_model.add(Conv2D(6, kernel_size=(3, 3), activation='relu', input_shape=(30, 62, 1)))\n",
    "eyes_emotion_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "eyes_emotion_model.add(Conv2D(16, kernel_size=(3, 3), activation='relu', input_shape=(14, 30, 6)))\n",
    "eyes_emotion_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "eyes_emotion_model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(6, 14, 16)))\n",
    "eyes_emotion_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "eyes_emotion_model.add(Flatten(name=\"eyes_flatten\"))\n",
    "\n",
    "eyes_emotion_model.add(Dense(1024, activation='relu'))\n",
    "eyes_emotion_model.add(Dropout(0.25))\n",
    "\n",
    "eyes_emotion_model.add(Dense(7, activation='softmax'))\n",
    "\n",
    "eyes_emotion_model.compile(loss='categorical_crossentropy', optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.0001, decay=1e-6), metrics=['accuracy'])\n",
    "\n",
    "eyes_emotion_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_9 (Conv2D)           (None, 28, 36, 6)         60        \n",
      "                                                                 \n",
      " max_pooling2d_9 (MaxPoolin  (None, 14, 18, 6)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          (None, 12, 16, 16)        880       \n",
      "                                                                 \n",
      " max_pooling2d_10 (MaxPooli  (None, 6, 8, 16)          0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 4, 6, 32)          4640      \n",
      "                                                                 \n",
      " max_pooling2d_11 (MaxPooli  (None, 2, 3, 32)          0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " mouth_flatten (Flatten)     (None, 192)               0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 1024)              197632    \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 7)                 7175      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 210387 (821.82 KB)\n",
      "Trainable params: 210387 (821.82 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# variance\n",
    "\n",
    "mouth_emotion_model = Sequential()\n",
    "\n",
    "mouth_emotion_model.add(Conv2D(6, kernel_size=(3, 3), activation='relu', input_shape=(30, 38, 1)))\n",
    "mouth_emotion_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "mouth_emotion_model.add(Conv2D(16, kernel_size=(3, 3), activation='relu', input_shape=(14, 18, 6)))\n",
    "mouth_emotion_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "mouth_emotion_model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(6, 8, 16)))\n",
    "mouth_emotion_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "mouth_emotion_model.add(Flatten(name=\"mouth_flatten\"))\n",
    "\n",
    "mouth_emotion_model.add(Dense(1024, activation='relu'))\n",
    "mouth_emotion_model.add(Dropout(0.25))\n",
    "\n",
    "mouth_emotion_model.add(Dense(7, activation='softmax'))\n",
    "\n",
    "mouth_emotion_model.compile(loss='categorical_crossentropy', optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.0001, decay=1e-6), metrics=['accuracy'])\n",
    "\n",
    "mouth_emotion_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "flatten_face = face_emotion_model.get_layer('face_flatten').output\n",
    "flatten_eyes = eyes_emotion_model.get_layer('eyes_flatten').output\n",
    "flatten_mouth = mouth_emotion_model.get_layer('mouth_flatten').output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concatenate Face Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv_1_input (InputLayer)   [(None, 38, 38, 1)]       0         \n",
      "                                                                 \n",
      " conv_1 (Conv2D)             (None, 36, 36, 6)         60        \n",
      "                                                                 \n",
      " pool_1 (MaxPooling2D)       (None, 18, 18, 6)         0         \n",
      "                                                                 \n",
      " conv_2 (Conv2D)             (None, 16, 16, 16)        880       \n",
      "                                                                 \n",
      " pool_2 (MaxPooling2D)       (None, 8, 8, 16)          0         \n",
      "                                                                 \n",
      " conv_3 (Conv2D)             (None, 6, 6, 32)          4640      \n",
      "                                                                 \n",
      " pool_3 (MaxPooling2D)       (None, 3, 3, 32)          0         \n",
      "                                                                 \n",
      " face_flatten (Flatten)      (None, 288)               0         \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 824)               238136    \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 824)               0         \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 7)                 5775      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 249491 (974.57 KB)\n",
      "Trainable params: 249491 (974.57 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "new_model = Dense(824, activation='relu')(flatten_face)\n",
    "new_model = Dropout(0.5)(new_model)\n",
    "new_model = Dense(7, activation='softmax')(new_model)\n",
    "\n",
    "# Create the final model\n",
    "final_model = Model(inputs=face_emotion_model.input, outputs=new_model)\n",
    "\n",
    "# Compile the final model with an appropriate optimizer, loss, and metrics\n",
    "final_model.compile(loss='categorical_crossentropy', \n",
    "                    optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.0001, decay=1e-6), \n",
    "                    metrics=['accuracy'])\n",
    "\n",
    "# Display the summary of the final model\n",
    "final_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "12/12 [==============================] - 2s 79ms/step - loss: 1.9429 - accuracy: 0.1770 - val_loss: 1.9478 - val_accuracy: 0.1797\n",
      "Epoch 2/150\n",
      "12/12 [==============================] - 1s 44ms/step - loss: 1.9398 - accuracy: 0.1826 - val_loss: 1.9525 - val_accuracy: 0.1562\n",
      "Epoch 3/150\n",
      "12/12 [==============================] - 1s 41ms/step - loss: 1.9334 - accuracy: 0.2051 - val_loss: 1.9587 - val_accuracy: 0.0859\n",
      "Epoch 4/150\n",
      "12/12 [==============================] - 0s 40ms/step - loss: 1.9314 - accuracy: 0.2219 - val_loss: 1.9658 - val_accuracy: 0.1250\n",
      "Epoch 5/150\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 1.9265 - accuracy: 0.1910 - val_loss: 1.9572 - val_accuracy: 0.1172\n",
      "Epoch 6/150\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 1.9226 - accuracy: 0.2205 - val_loss: 1.9651 - val_accuracy: 0.1250\n",
      "Epoch 7/150\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 1.9181 - accuracy: 0.2177 - val_loss: 1.9629 - val_accuracy: 0.1250\n",
      "Epoch 8/150\n",
      "12/12 [==============================] - 0s 36ms/step - loss: 1.9200 - accuracy: 0.1896 - val_loss: 1.9814 - val_accuracy: 0.1328\n",
      "Epoch 9/150\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 1.9211 - accuracy: 0.2022 - val_loss: 1.9981 - val_accuracy: 0.1094\n",
      "Epoch 10/150\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 1.9200 - accuracy: 0.2008 - val_loss: 1.9666 - val_accuracy: 0.1328\n",
      "Epoch 11/150\n",
      "12/12 [==============================] - 1s 41ms/step - loss: 1.9109 - accuracy: 0.2044 - val_loss: 1.9633 - val_accuracy: 0.1406\n",
      "Epoch 12/150\n",
      "12/12 [==============================] - 1s 41ms/step - loss: 1.9113 - accuracy: 0.2205 - val_loss: 1.9743 - val_accuracy: 0.1328\n",
      "Epoch 13/150\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 1.9055 - accuracy: 0.2289 - val_loss: 1.9603 - val_accuracy: 0.1484\n",
      "Epoch 14/150\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 1.9010 - accuracy: 0.2416 - val_loss: 1.9666 - val_accuracy: 0.2109\n",
      "Epoch 15/150\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 1.8945 - accuracy: 0.2528 - val_loss: 1.9531 - val_accuracy: 0.2188\n",
      "Epoch 16/150\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 1.8910 - accuracy: 0.2725 - val_loss: 1.9510 - val_accuracy: 0.2031\n",
      "Epoch 17/150\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 1.8836 - accuracy: 0.2747 - val_loss: 1.9501 - val_accuracy: 0.2344\n",
      "Epoch 18/150\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 1.8738 - accuracy: 0.2837 - val_loss: 1.9528 - val_accuracy: 0.1953\n",
      "Epoch 19/150\n",
      "12/12 [==============================] - 1s 47ms/step - loss: 1.8628 - accuracy: 0.2767 - val_loss: 1.9413 - val_accuracy: 0.2031\n",
      "Epoch 20/150\n",
      "12/12 [==============================] - 1s 53ms/step - loss: 1.8479 - accuracy: 0.2949 - val_loss: 1.9473 - val_accuracy: 0.1797\n",
      "Epoch 21/150\n",
      "12/12 [==============================] - 1s 55ms/step - loss: 1.8378 - accuracy: 0.2995 - val_loss: 1.9355 - val_accuracy: 0.2266\n",
      "Epoch 22/150\n",
      "12/12 [==============================] - 1s 48ms/step - loss: 1.8331 - accuracy: 0.3076 - val_loss: 1.9234 - val_accuracy: 0.2500\n",
      "Epoch 23/150\n",
      "12/12 [==============================] - 1s 48ms/step - loss: 1.8119 - accuracy: 0.3272 - val_loss: 1.9175 - val_accuracy: 0.2578\n",
      "Epoch 24/150\n",
      "12/12 [==============================] - 1s 48ms/step - loss: 1.7936 - accuracy: 0.3272 - val_loss: 1.9098 - val_accuracy: 0.2500\n",
      "Epoch 25/150\n",
      "12/12 [==============================] - 1s 50ms/step - loss: 1.7741 - accuracy: 0.3455 - val_loss: 1.9115 - val_accuracy: 0.2031\n",
      "Epoch 26/150\n",
      "12/12 [==============================] - 1s 48ms/step - loss: 1.7466 - accuracy: 0.3427 - val_loss: 1.8988 - val_accuracy: 0.2109\n",
      "Epoch 27/150\n",
      "12/12 [==============================] - 1s 54ms/step - loss: 1.7217 - accuracy: 0.3525 - val_loss: 1.8951 - val_accuracy: 0.2188\n",
      "Epoch 28/150\n",
      "12/12 [==============================] - 1s 48ms/step - loss: 1.7121 - accuracy: 0.3652 - val_loss: 1.9408 - val_accuracy: 0.2266\n",
      "Epoch 29/150\n",
      "12/12 [==============================] - 0s 40ms/step - loss: 1.6670 - accuracy: 0.3862 - val_loss: 1.9182 - val_accuracy: 0.2734\n",
      "Epoch 30/150\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 1.6582 - accuracy: 0.3497 - val_loss: 1.8725 - val_accuracy: 0.2344\n",
      "Epoch 31/150\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 1.6352 - accuracy: 0.3904 - val_loss: 1.8722 - val_accuracy: 0.2500\n",
      "Epoch 32/150\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 1.6286 - accuracy: 0.3806 - val_loss: 1.8820 - val_accuracy: 0.2969\n",
      "Epoch 33/150\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 1.6102 - accuracy: 0.3764 - val_loss: 1.8830 - val_accuracy: 0.2578\n",
      "Epoch 34/150\n",
      "12/12 [==============================] - 0s 40ms/step - loss: 1.5994 - accuracy: 0.3947 - val_loss: 1.9511 - val_accuracy: 0.1797\n",
      "Epoch 35/150\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 1.5668 - accuracy: 0.4045 - val_loss: 1.8597 - val_accuracy: 0.2656\n",
      "Epoch 36/150\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 1.5577 - accuracy: 0.4242 - val_loss: 1.8745 - val_accuracy: 0.2500\n",
      "Epoch 37/150\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 1.5437 - accuracy: 0.4284 - val_loss: 1.9490 - val_accuracy: 0.2812\n",
      "Epoch 38/150\n",
      "12/12 [==============================] - 0s 40ms/step - loss: 1.5261 - accuracy: 0.4256 - val_loss: 1.9429 - val_accuracy: 0.2734\n",
      "Epoch 39/150\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 1.5134 - accuracy: 0.4059 - val_loss: 1.9111 - val_accuracy: 0.2812\n",
      "Epoch 40/150\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 1.4958 - accuracy: 0.4143 - val_loss: 1.9880 - val_accuracy: 0.2422\n",
      "Epoch 41/150\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 1.4798 - accuracy: 0.4199 - val_loss: 1.9637 - val_accuracy: 0.2109\n",
      "Epoch 42/150\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 1.4668 - accuracy: 0.4185 - val_loss: 1.8957 - val_accuracy: 0.2656\n",
      "Epoch 43/150\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 1.4522 - accuracy: 0.4635 - val_loss: 1.9805 - val_accuracy: 0.2500\n",
      "Epoch 44/150\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 1.4475 - accuracy: 0.4480 - val_loss: 1.9425 - val_accuracy: 0.2422\n",
      "Epoch 45/150\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 1.4489 - accuracy: 0.4607 - val_loss: 1.9276 - val_accuracy: 0.2188\n",
      "Epoch 46/150\n",
      "12/12 [==============================] - 0s 40ms/step - loss: 1.4436 - accuracy: 0.4719 - val_loss: 1.8869 - val_accuracy: 0.2891\n",
      "Epoch 47/150\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 1.4151 - accuracy: 0.4466 - val_loss: 2.0153 - val_accuracy: 0.2656\n",
      "Epoch 48/150\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 1.4161 - accuracy: 0.4438 - val_loss: 1.9367 - val_accuracy: 0.2812\n",
      "Epoch 49/150\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 1.4034 - accuracy: 0.4579 - val_loss: 1.9016 - val_accuracy: 0.2734\n",
      "Epoch 50/150\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 1.3955 - accuracy: 0.4779 - val_loss: 1.9918 - val_accuracy: 0.2891\n",
      "Epoch 51/150\n",
      "12/12 [==============================] - 0s 40ms/step - loss: 1.3711 - accuracy: 0.4817 - val_loss: 1.9926 - val_accuracy: 0.2188\n",
      "Epoch 52/150\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 1.3549 - accuracy: 0.5028 - val_loss: 2.0425 - val_accuracy: 0.2188\n",
      "Epoch 53/150\n",
      "12/12 [==============================] - 0s 41ms/step - loss: 1.3635 - accuracy: 0.4846 - val_loss: 1.9850 - val_accuracy: 0.2422\n",
      "Epoch 54/150\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 1.3503 - accuracy: 0.4916 - val_loss: 2.0406 - val_accuracy: 0.2734\n",
      "Epoch 55/150\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 1.3666 - accuracy: 0.4761 - val_loss: 2.0224 - val_accuracy: 0.2656\n",
      "Epoch 56/150\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 1.3397 - accuracy: 0.4874 - val_loss: 1.9699 - val_accuracy: 0.2500\n",
      "Epoch 57/150\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 1.3245 - accuracy: 0.5000 - val_loss: 1.9811 - val_accuracy: 0.2578\n",
      "Epoch 58/150\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 1.3262 - accuracy: 0.4803 - val_loss: 2.0917 - val_accuracy: 0.2500\n",
      "Epoch 59/150\n",
      "12/12 [==============================] - 0s 40ms/step - loss: 1.3485 - accuracy: 0.4747 - val_loss: 1.9878 - val_accuracy: 0.2656\n",
      "Epoch 60/150\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 1.3310 - accuracy: 0.5042 - val_loss: 2.0641 - val_accuracy: 0.2578\n",
      "Epoch 61/150\n",
      "12/12 [==============================] - 1s 41ms/step - loss: 1.3048 - accuracy: 0.5098 - val_loss: 2.0299 - val_accuracy: 0.2188\n",
      "Epoch 62/150\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 1.2924 - accuracy: 0.4916 - val_loss: 2.2316 - val_accuracy: 0.2188\n",
      "Epoch 63/150\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 1.2964 - accuracy: 0.5197 - val_loss: 2.0003 - val_accuracy: 0.2188\n",
      "Epoch 64/150\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 1.2976 - accuracy: 0.5126 - val_loss: 1.9287 - val_accuracy: 0.2812\n",
      "Epoch 65/150\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 1.2779 - accuracy: 0.5239 - val_loss: 2.1489 - val_accuracy: 0.1953\n",
      "Epoch 66/150\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 1.2827 - accuracy: 0.5154 - val_loss: 2.0635 - val_accuracy: 0.2266\n",
      "Epoch 67/150\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 1.2709 - accuracy: 0.5169 - val_loss: 2.0890 - val_accuracy: 0.2500\n",
      "Epoch 68/150\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 1.2554 - accuracy: 0.5225 - val_loss: 2.1699 - val_accuracy: 0.2344\n",
      "Epoch 69/150\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 1.2504 - accuracy: 0.5253 - val_loss: 2.0943 - val_accuracy: 0.1875\n",
      "Epoch 70/150\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 1.2678 - accuracy: 0.5169 - val_loss: 2.0997 - val_accuracy: 0.2344\n",
      "Epoch 71/150\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 1.2636 - accuracy: 0.5197 - val_loss: 2.0657 - val_accuracy: 0.2344\n",
      "Epoch 72/150\n",
      "12/12 [==============================] - 0s 36ms/step - loss: 1.2433 - accuracy: 0.5281 - val_loss: 2.1961 - val_accuracy: 0.2266\n",
      "Epoch 73/150\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 1.2323 - accuracy: 0.5323 - val_loss: 2.2262 - val_accuracy: 0.2031\n",
      "Epoch 74/150\n",
      "12/12 [==============================] - 1s 40ms/step - loss: 1.2439 - accuracy: 0.5195 - val_loss: 2.2794 - val_accuracy: 0.1719\n",
      "Epoch 75/150\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 1.2422 - accuracy: 0.5295 - val_loss: 2.1085 - val_accuracy: 0.2188\n",
      "Epoch 76/150\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 1.2269 - accuracy: 0.5562 - val_loss: 2.1704 - val_accuracy: 0.2500\n",
      "Epoch 77/150\n",
      "12/12 [==============================] - 1s 41ms/step - loss: 1.2121 - accuracy: 0.5417 - val_loss: 2.1283 - val_accuracy: 0.2734\n",
      "Epoch 78/150\n",
      "12/12 [==============================] - 0s 40ms/step - loss: 1.2171 - accuracy: 0.5463 - val_loss: 2.1953 - val_accuracy: 0.2344\n",
      "Epoch 79/150\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 1.2175 - accuracy: 0.5337 - val_loss: 2.3150 - val_accuracy: 0.2344\n",
      "Epoch 80/150\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 1.2025 - accuracy: 0.5435 - val_loss: 2.1085 - val_accuracy: 0.2578\n",
      "Epoch 81/150\n",
      "12/12 [==============================] - 0s 40ms/step - loss: 1.2022 - accuracy: 0.5337 - val_loss: 2.2609 - val_accuracy: 0.2109\n",
      "Epoch 82/150\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 1.1919 - accuracy: 0.5548 - val_loss: 2.1993 - val_accuracy: 0.2266\n",
      "Epoch 83/150\n",
      "12/12 [==============================] - 1s 45ms/step - loss: 1.1909 - accuracy: 0.5478 - val_loss: 2.1854 - val_accuracy: 0.2344\n",
      "Epoch 84/150\n",
      "12/12 [==============================] - 1s 46ms/step - loss: 1.1959 - accuracy: 0.5449 - val_loss: 2.1856 - val_accuracy: 0.2578\n",
      "Epoch 85/150\n",
      "12/12 [==============================] - 1s 40ms/step - loss: 1.2108 - accuracy: 0.5211 - val_loss: 1.9698 - val_accuracy: 0.2578\n",
      "Epoch 86/150\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 1.1910 - accuracy: 0.5492 - val_loss: 1.9554 - val_accuracy: 0.2578\n",
      "Epoch 87/150\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 1.1913 - accuracy: 0.5590 - val_loss: 2.1376 - val_accuracy: 0.2812\n",
      "Epoch 88/150\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 1.1652 - accuracy: 0.5772 - val_loss: 2.1311 - val_accuracy: 0.2500\n",
      "Epoch 89/150\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 1.1754 - accuracy: 0.5787 - val_loss: 2.2447 - val_accuracy: 0.1953\n",
      "Epoch 90/150\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 1.1656 - accuracy: 0.5562 - val_loss: 2.2813 - val_accuracy: 0.2266\n",
      "Epoch 91/150\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 1.1780 - accuracy: 0.5337 - val_loss: 2.2652 - val_accuracy: 0.2266\n",
      "Epoch 92/150\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 1.1540 - accuracy: 0.5660 - val_loss: 2.0831 - val_accuracy: 0.2812\n",
      "Epoch 93/150\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 1.1656 - accuracy: 0.5632 - val_loss: 2.1800 - val_accuracy: 0.2656\n",
      "Epoch 94/150\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 1.1737 - accuracy: 0.5586 - val_loss: 2.2470 - val_accuracy: 0.2266\n",
      "Epoch 95/150\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 1.1383 - accuracy: 0.5787 - val_loss: 2.0815 - val_accuracy: 0.2578\n",
      "Epoch 96/150\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 1.1321 - accuracy: 0.5772 - val_loss: 2.2169 - val_accuracy: 0.2422\n",
      "Epoch 97/150\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 1.1635 - accuracy: 0.5393 - val_loss: 2.0636 - val_accuracy: 0.2734\n",
      "Epoch 98/150\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 1.1471 - accuracy: 0.5716 - val_loss: 2.1595 - val_accuracy: 0.2188\n",
      "Epoch 99/150\n",
      "12/12 [==============================] - 1s 42ms/step - loss: 1.1491 - accuracy: 0.5660 - val_loss: 2.1046 - val_accuracy: 0.2969\n",
      "Epoch 100/150\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 1.1204 - accuracy: 0.5955 - val_loss: 2.3242 - val_accuracy: 0.2344\n",
      "Epoch 101/150\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 1.1511 - accuracy: 0.5534 - val_loss: 2.1620 - val_accuracy: 0.2422\n",
      "Epoch 102/150\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 1.1196 - accuracy: 0.5646 - val_loss: 2.2408 - val_accuracy: 0.2344\n",
      "Epoch 103/150\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 1.1148 - accuracy: 0.5997 - val_loss: 2.2947 - val_accuracy: 0.2031\n",
      "Epoch 104/150\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 1.1359 - accuracy: 0.5801 - val_loss: 2.1639 - val_accuracy: 0.2578\n",
      "Epoch 105/150\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 1.0675 - accuracy: 0.6138 - val_loss: 2.2211 - val_accuracy: 0.2500\n",
      "Epoch 106/150\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 1.1176 - accuracy: 0.5787 - val_loss: 2.1209 - val_accuracy: 0.2344\n",
      "Epoch 107/150\n",
      "12/12 [==============================] - 1s 37ms/step - loss: 1.1196 - accuracy: 0.5843 - val_loss: 2.1788 - val_accuracy: 0.2578\n",
      "Epoch 108/150\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 1.1115 - accuracy: 0.5913 - val_loss: 2.3434 - val_accuracy: 0.2031\n",
      "Epoch 109/150\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 1.1006 - accuracy: 0.5899 - val_loss: 2.3083 - val_accuracy: 0.2109\n",
      "Epoch 110/150\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 1.1149 - accuracy: 0.5688 - val_loss: 2.2512 - val_accuracy: 0.2109\n",
      "Epoch 111/150\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 1.1134 - accuracy: 0.5871 - val_loss: 2.3383 - val_accuracy: 0.2578\n",
      "Epoch 112/150\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 1.0675 - accuracy: 0.5969 - val_loss: 2.3390 - val_accuracy: 0.2344\n",
      "Epoch 113/150\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 1.0980 - accuracy: 0.5885 - val_loss: 2.2038 - val_accuracy: 0.2500\n",
      "Epoch 114/150\n",
      "12/12 [==============================] - 1s 40ms/step - loss: 1.0972 - accuracy: 0.5997 - val_loss: 2.1416 - val_accuracy: 0.2188\n",
      "Epoch 115/150\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 1.0619 - accuracy: 0.6166 - val_loss: 2.2979 - val_accuracy: 0.2266\n",
      "Epoch 116/150\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 1.0676 - accuracy: 0.6110 - val_loss: 2.1692 - val_accuracy: 0.2891\n",
      "Epoch 117/150\n",
      "12/12 [==============================] - 0s 40ms/step - loss: 1.0852 - accuracy: 0.6081 - val_loss: 2.1958 - val_accuracy: 0.2422\n",
      "Epoch 118/150\n",
      "12/12 [==============================] - 0s 40ms/step - loss: 1.0965 - accuracy: 0.5758 - val_loss: 2.2029 - val_accuracy: 0.2109\n",
      "Epoch 119/150\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 1.0747 - accuracy: 0.6198 - val_loss: 2.2026 - val_accuracy: 0.2422\n",
      "Epoch 120/150\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 1.0739 - accuracy: 0.5941 - val_loss: 2.1742 - val_accuracy: 0.2422\n",
      "Epoch 121/150\n",
      "12/12 [==============================] - 1s 42ms/step - loss: 1.0438 - accuracy: 0.6236 - val_loss: 2.2881 - val_accuracy: 0.1875\n",
      "Epoch 122/150\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 1.1018 - accuracy: 0.5815 - val_loss: 2.2233 - val_accuracy: 0.2266\n",
      "Epoch 123/150\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 1.0527 - accuracy: 0.6011 - val_loss: 2.2106 - val_accuracy: 0.2656\n",
      "Epoch 124/150\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 1.0532 - accuracy: 0.6067 - val_loss: 2.2353 - val_accuracy: 0.2734\n",
      "Epoch 125/150\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 1.0434 - accuracy: 0.6124 - val_loss: 2.1343 - val_accuracy: 0.2422\n",
      "Epoch 126/150\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 1.0497 - accuracy: 0.6180 - val_loss: 2.3636 - val_accuracy: 0.2188\n",
      "Epoch 127/150\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 1.0744 - accuracy: 0.6110 - val_loss: 2.2548 - val_accuracy: 0.2500\n",
      "Epoch 128/150\n",
      "12/12 [==============================] - 1s 42ms/step - loss: 1.0490 - accuracy: 0.5997 - val_loss: 2.0550 - val_accuracy: 0.3125\n",
      "Epoch 129/150\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 1.0469 - accuracy: 0.6180 - val_loss: 2.2827 - val_accuracy: 0.2344\n",
      "Epoch 130/150\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 1.0600 - accuracy: 0.6152 - val_loss: 2.2218 - val_accuracy: 0.2656\n",
      "Epoch 131/150\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 1.0278 - accuracy: 0.6138 - val_loss: 2.0836 - val_accuracy: 0.2344\n",
      "Epoch 132/150\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 1.0497 - accuracy: 0.6039 - val_loss: 2.1756 - val_accuracy: 0.2422\n",
      "Epoch 133/150\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 1.0149 - accuracy: 0.6180 - val_loss: 2.1386 - val_accuracy: 0.2891\n",
      "Epoch 134/150\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 1.0442 - accuracy: 0.6278 - val_loss: 2.1829 - val_accuracy: 0.2656\n",
      "Epoch 135/150\n",
      "12/12 [==============================] - 1s 45ms/step - loss: 1.0286 - accuracy: 0.6152 - val_loss: 2.2041 - val_accuracy: 0.2578\n",
      "Epoch 136/150\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 1.0583 - accuracy: 0.6011 - val_loss: 2.1560 - val_accuracy: 0.2656\n",
      "Epoch 137/150\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 1.0302 - accuracy: 0.6096 - val_loss: 2.1332 - val_accuracy: 0.2422\n",
      "Epoch 138/150\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 1.0340 - accuracy: 0.6096 - val_loss: 2.1719 - val_accuracy: 0.2422\n",
      "Epoch 139/150\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 1.0322 - accuracy: 0.6208 - val_loss: 2.2244 - val_accuracy: 0.2578\n",
      "Epoch 140/150\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 1.0257 - accuracy: 0.6236 - val_loss: 2.2074 - val_accuracy: 0.2812\n",
      "Epoch 141/150\n",
      "12/12 [==============================] - 0s 40ms/step - loss: 1.0303 - accuracy: 0.6250 - val_loss: 2.1502 - val_accuracy: 0.2734\n",
      "Epoch 142/150\n",
      "12/12 [==============================] - 1s 41ms/step - loss: 1.0231 - accuracy: 0.6236 - val_loss: 2.2736 - val_accuracy: 0.2031\n",
      "Epoch 143/150\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 1.0322 - accuracy: 0.6011 - val_loss: 2.2883 - val_accuracy: 0.2500\n",
      "Epoch 144/150\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 0.9929 - accuracy: 0.6475 - val_loss: 2.2668 - val_accuracy: 0.2500\n",
      "Epoch 145/150\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 0.9980 - accuracy: 0.6208 - val_loss: 2.2683 - val_accuracy: 0.2422\n",
      "Epoch 146/150\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 1.0189 - accuracy: 0.6166 - val_loss: 2.1370 - val_accuracy: 0.2500\n",
      "Epoch 147/150\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 1.0233 - accuracy: 0.6250 - val_loss: 2.2091 - val_accuracy: 0.3047\n",
      "Epoch 148/150\n",
      "12/12 [==============================] - 0s 41ms/step - loss: 1.0242 - accuracy: 0.6194 - val_loss: 2.2271 - val_accuracy: 0.2266\n",
      "Epoch 149/150\n",
      "12/12 [==============================] - 1s 37ms/step - loss: 0.9780 - accuracy: 0.6503 - val_loss: 2.1464 - val_accuracy: 0.2578\n",
      "Epoch 150/150\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 0.9966 - accuracy: 0.6489 - val_loss: 2.2669 - val_accuracy: 0.2422\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x21fccb87b50>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model.fit(\n",
    "    face_train_generator,\n",
    "    steps_per_epoch= 776 // 64,\n",
    "    epochs=150,\n",
    "    validation_data=face_valid_generator,\n",
    "    validation_steps= 181 // 64  \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concatenate All Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenated_features = Concatenate(axis=-1)([flatten_face, flatten_eyes, flatten_mouth])\n",
    "# reshaped_features = Reshape((864, 1))(concatenated_features)\n",
    "\n",
    "# output_layer = Dense(7, activation='softmax')(reshaped_features)\n",
    "\n",
    "# feature_fusion_model = Model(inputs=[face_emotion_model.input, eyes_emotion_model.input, mouth_emotion_model.input], outputs=output_layer)\n",
    "\n",
    "# feature_fusion_model.compile(loss='categorical_crossentropy', optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.0001, decay=1e-6), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_fusion_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train =  feature_fusion_model.fit(\n",
    "#     x=[face_train_generator, eyes_train_generator, mouth_train_generator],\n",
    "#     steps_per_epoch= 776 // 64,\n",
    "#     epochs=10,\n",
    "#     validation_data=[(face_valid_generator, eyes_valid_generator, mouth_valid_generator)],\n",
    "#     validation_steps= 181 // 64  \n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "###### ├── train/\n",
    "###### │   ├── face_train/\n",
    "###### │   │   ├── image1.jpg\n",
    "###### │   │   ├── image2.jpg\n",
    "###### │   │   └── ...\n",
    "###### │   ├── eyes_train/\n",
    "###### │   │   ├── image1.jpg\n",
    "###### │   │   ├── image2.jpg\n",
    "###### │   │   └── ...\n",
    "###### │   └── mouth_train/\n",
    "###### │       ├── image1.jpg\n",
    "###### │       ├── image2.jpg\n",
    "###### │       └── ...\n",
    "###### └── test/\n",
    "######     ├── face_test/\n",
    "######     │   ├── image1.jpg\n",
    "######     │   ├── image2.jpg\n",
    "######     │   └── ...\n",
    "######     ├── eyes_test/\n",
    "######     │   ├── image1.jpg\n",
    "######     │   ├── image2.jpg\n",
    "######     │   └── ...\n",
    "######     └── mouth_test/\n",
    "######         ├── image1.jpg\n",
    "######         ├── image2.jpg\n",
    "######         └── ..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
